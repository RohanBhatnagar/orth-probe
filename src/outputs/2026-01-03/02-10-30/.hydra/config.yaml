model:
  name: meta-llama/Meta-Llama-3-8B
  dtype: bfloat16
  device: cuda
dataset:
  max_new_tokens: 512
  temperature: 0.7
  stop_at_eos: true
generation: {}
seed: 42
num_samples: 100
layers:
- 0
- 1
- 2
- 3
- 4
- 5
- 6
- 7
- 8
- 9
- 10
- 11
- 12
- 13
- 14
- 15
- 16
- 17
- 18
- 19
- 20
- 21
- 22
- 23
- 24
- 25
- 26
- 27
- 28
- 29
- 30
- 31
- 32
- 33
output_dir: /data
